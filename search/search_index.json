{"config":{"lang":["zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ABFML","text":"<p>ABFML (A problem-oriented package for rapidly creating, screening, and optimizing new machine learning force fields) is a Python-based toolkit designed to streamline the development, training, and deployment of machine learning force fields (MLFFs). It integrates modern deep learning frameworks and molecular dynamics engines, enabling efficient model construction and application.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Rapid construction of MLFF models based on physical descriptors</li> <li>Support for large-scale molecular dynamics via LAMMPS and ASE</li> <li>Modular design for easy extension and research customization</li> </ul>"},{"location":"#quickstart","title":"Quickstart","text":"<p><pre><code>pip install abfml\n</code></pre> For more details, check the Installation Guide and Tutorials.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Installation</li> <li>Tutorials</li> <li>API Reference</li> <li>Citation</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use ABFML in your research, please cite:</p> <p>Xingze Geng, Jianing Gu, Gaowu Qin, Lin-Wang Wang, Xiangying Meng. ABFML: A problem-oriented package for rapidly creating, screening, and optimizing new machine learning force fields. J. Chem. Phys. 162, 052502 (2025). https://doi.org/10.1063/5.0247559</p>"},{"location":"citation/","title":"Citation","text":"<p>If you use ABFML in your research, please cite the following paper:</p> <p>Xingze Geng, Jianing Gu, Gaowu Qin, Lin-Wang Wang, Xiangying Meng. ABFML: A problem-oriented package for rapidly creating, screening, and optimizing new machine learning force fields. Journal of Chemical Physics 162, 052502 (2025). https://doi.org/10.1063/5.0247559</p>"},{"location":"citation/#bibtex","title":"BibTeX","text":"<pre><code>@article{ABFML2025,\n  author  = {Xingze Geng and Jianing Gu and Gaowu Qin and Lin-Wang Wang and Xiangying Meng},\n  title   = {ABFML: A problem-oriented package for rapidly creating, screening, and optimizing new machine learning force fields},\n  journal = {Journal of Chemical Physics},\n  year    = {2025},\n  volume  = {162},\n  number  = {5},\n  pages   = {052502},\n  doi     = {10.1063/5.0247559}\n}\n</code></pre>"},{"location":"cli/","title":"Command-Line Interface (CLI)","text":"<p>ABFML provides a command-line interface for quick model checking, training, and validation. You can display general help using: <pre><code>abfml --help\n</code></pre></p>"},{"location":"cli/#available-commands","title":"Available Commands","text":""},{"location":"cli/#check","title":"<code>check</code>","text":"<p>Check the validity and inference capability of a trained model. <pre><code>abfml check -m model.pt -d float32\n</code></pre> - Purpose: Ensures the model file can be loaded and used for inference.</p>"},{"location":"cli/#train","title":"<code>train</code>","text":"<p>Start training a machine learning force field model based on a configuration file. <pre><code>abfml train input.json\n</code></pre> - Purpose: Launches the training process using parameters defined in <code>input.json</code>.</p>"},{"location":"cli/#valid","title":"<code>valid</code>","text":"<p>Validate a trained model using a test dataset. <pre><code>abfml valid -m model.pt -f \"../data/test.extxyz\" -n 10\n</code></pre> - Purpose: Evaluates model performance with specified test data and sample size.</p>"},{"location":"cli/#help-for-commands","title":"Help for Commands","text":"<p>Each command provides detailed parameter information using <code>-h</code>: <pre><code>abfml train -h\nabfml valid -h\nabfml check -h\n</code></pre></p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#1-installing-abfml","title":"1. Installing ABFML","text":"<p>To quickly get started with ABFML, set up an isolated Python environment and install the package.</p> <pre><code># 1. Create a new conda environment\nconda create -n abfml python=3.11\n\n# 2. Activate the environment\nconda activate abfml\n\n# 3. Install ABFML\n\n# Option 1: Install from source (recommended for development)\ncd path/to/ABFML\npip install .\n\n# Option 2: Install from PyPI (for general use)\npip install abfml\n</code></pre>"},{"location":"install/#2-installing-abfml-lammps-optional","title":"2. Installing ABFML-LAMMPS (Optional)","text":"<p>This step is only required if you plan to run large-scale molecular dynamics simulations  with LAMMPS using ABFML-generated force fields. For initial model development and testing, ABFML works directly with ASE and you can skip this section.</p>"},{"location":"install/#21-prerequisites","title":"2.1 Prerequisites","text":"<ol> <li> <p>LAMMPS    Download and build LAMMPS for your platform: LAMMPS Official Website</p> </li> <li> <p>Libtorch    Download the PyTorch C++ API (Libtorch).    If your system's toolchain is older, use the Pre-cxx11 ABI version.</p> </li> </ol>"},{"location":"install/#22-integration-steps","title":"2.2 Integration Steps","text":""},{"location":"install/#1-copy-abfml-files-into-lammps","title":"1. Copy ABFML files into LAMMPS","text":"<pre><code>cp abfml/lmp/ABFML lammps/src\ncp abfml/lmp/Makefile.mpi lammps/src/MAKE\n</code></pre>"},{"location":"install/#2-modify-makefilempi","title":"2. Modify <code>Makefile.mpi</code>","text":"<p>Edit <code>lammps/src/MAKE/Makefile.mpi</code> to match your system paths for compilers and libraries: <pre><code>CCFLAGS += -I/PATH/libtorch/include/\nCCFLAGS += -I/PATH/libtorch/include/torch/csrc/api/include/\nCCFLAGS += -I/PATH/libtorch\nLINKFLAGS += -L/PATH/libtorch/lib/ -ltorch -lc10 -ltorch_cpu\n</code></pre></p>"},{"location":"install/#3-build-lammps-with-abfml","title":"3. Build LAMMPS with ABFML","text":"<pre><code>export LD_LIBRARY_PATH=/path/libtorch/lib:$LD_LIBRARY_PATH\ncd lammps/src\nmake yes-abfml\nmake mpi\n</code></pre>"},{"location":"install/#23-running-lammps-with-abfml","title":"2.3 Running LAMMPS with ABFML","text":"<p>Example of using ABFML in an input script: <pre><code>pair_style abfml model.pt\npair_coeff * * 29 30\n</code></pre> Here, element numbers (e.g., <code>29</code>, <code>30</code>) represent element types.</p>"},{"location":"install/#notes","title":"Notes","text":"<ul> <li>Ensure that the Libtorch version matches the PyTorch version used for training the ABFML model.</li> <li>Always verify the correct <code>LD_LIBRARY_PATH</code> before running LAMMPS.</li> </ul>"},{"location":"api/core/model/method/","title":"abfml.core.model","text":""},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel","title":"<code>FieldModel</code>","text":"<p>               Bases: <code>Module</code>, <code>ABC</code></p> Source code in <code>abfml\\core\\model\\method.py</code> <pre><code>class FieldModel(nn.Module, ABC):\n    def __init__(self,\n                 type_map: List[int],\n                 cutoff: float,\n                 neighbor: Union[Dict[int, int],int]):\n        \"\"\"\n        Base class for field-based machine learning potential models.\n\n        Parameters\n        ----------\n        type_map : List[int]\n            A list mapping atomic species to integer indices used in the model.\n            For example, [0, 1, 2] might represent three different element types.\n\n        cutoff : float\n            Cutoff radius for neighbor searching.\n            Only atoms within this distance will be considered as neighbors.\n\n        neighbor : Union[Dict[int, int], int]\n            Maximum number of neighbors for each atom type (or a global value).\n            Used to define tensor sizes or guide model input structure.\n\n        Examples\n        --------\n        ```python\n        # Create a model with two element types, cutoff radius 6.0,\n        # and maximum 100 neighbors for element type 1.\n        model = FieldModel(type_map=[0, 1], cutoff=6.0, neighbor={1: 100})\n        \"\"\"\n        super(FieldModel, self).__init__()\n        self.type_map = type_map\n        self.neighbor = neighbor\n        self.cutoff = cutoff\n\n    def forward(self,\n                element_map: torch.Tensor,\n                central_atoms: torch.Tensor,\n                neighbor_indices: torch.Tensor,\n                neighbor_types: torch.Tensor,\n                neighbor_vectors: torch.Tensor,\n                n_ghost: int) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Main forward pass computing physical quantities\n        Args:\n            element_map: Atomic numbers mapped to indices [batch, n_atoms]\n            central_atoms: Central atom indices [batch, n_atoms]\n            neighbor_indices: Neighbor atom indices [batch, n_atoms, max_nbr]\n            neighbor_types: Neighbor atom types [batch, n_atoms, max_nbr]\n            neighbor_vectors: Relative position vectors [batch, n_atoms, max_nbr, 4]\n                              (distance, dx, dy, dz)\n            n_ghost: Number of ghost atoms in the system\n\n        Returns:\n            Tuple containing:\n            - Etot [batch, 1]\n            - Ei [batch, n_atoms, 1]\n            - force [batch, n_atoms, 3]\n            - virial tensor [batch, 9]\n            - atomic_virial [batch, n_atoms, 9]\n        \"\"\"\n        # Extract dimensions and tensor properties\n        batch, n_atoms, max_neighbor, _ = neighbor_vectors.shape\n        device, dtype = neighbor_vectors.device, neighbor_vectors.dtype\n\n        # Extract displacement vectors (dx, dy, dz) and enable autograd\n        relative_positions = neighbor_vectors[..., 1:]\n        relative_positions.requires_grad_(True)\n\n        # Recalculate distance norm for generalization and recombine into input vector\n        distance = torch.norm(relative_positions, dim=-1, keepdim=True)  # Shape: [batch, n_atoms, max_nbr, 1]\n        neighbor_vector = torch.cat([distance, relative_positions], dim=-1)  # Shape: [batch, n_atoms, max_nbr, 4]\n\n        # Call the user-defined field function to compute energy and optionally other properties\n        physics_info = self.field(\n            element_map=element_map,\n            central_atoms=central_atoms,\n            neighbor_indices=neighbor_indices,\n            neighbor_types=neighbor_types,\n            neighbor_vectors=neighbor_vector,\n            n_ghost=n_ghost\n        )\n\n        # Required outputs\n        Etot = physics_info['Etot']  # Total energy per configuration, shape: [batch, 1]\n        Ei = physics_info['Ei']  # Per-atom energy, shape: [batch, n_atoms, 1]\n\n        # Validate required outputs\n        if Etot is None or not isinstance(Etot, torch.Tensor) or Etot.shape != (batch, 1):\n            raise ValueError(\"physics_info['Etot'] must be a torch.Tensor of shape (batch, 1)\")\n        if Ei is None or not isinstance(Ei, torch.Tensor) or Ei.shape != (batch, n_atoms, 1):\n            raise ValueError(\"physics_info['Ei'] must be a torch.Tensor of shape (batch, n_atoms, 1)\")\n\n        # If force is not provided, compute it via autograd\n        if physics_info.get('Force') is None:\n            # Create a gradient mask for backpropagation\n            energy_mask: List[Optional[torch.Tensor]] = [torch.ones_like(Ei)]\n\n            # Compute gradient of Ei with respect to atomic positions\n            grad_Ei = torch.autograd.grad(\n                outputs=[Ei],\n                inputs=[relative_positions],\n                grad_outputs=energy_mask,\n                retain_graph=True,\n                create_graph=True\n            )[0]\n            assert grad_Ei is not None\n\n            # Compute force, virial tensor, and atomic-level virial from gradients\n            force, virial, atomic_virial = derive_mechanics(\n                grad_Ei=grad_Ei,\n                neighbor_vectors=neighbor_vector,\n                neighbor_indices=neighbor_indices,\n                n_ghost=n_ghost\n            )\n        else:\n            # If force is provided by field, validate its shape\n            force = physics_info['Force']\n            if not isinstance(force, torch.Tensor) or force.shape != (batch, n_atoms, 3):\n                raise ValueError(\"physics_info['Force'] must be a torch.Tensor of shape (batch, n_atoms, 3)\")\n\n            # Optional: check for virial tensor\n            virial = physics_info.get('virial')\n            if virial is not None:\n                if not isinstance(virial, torch.Tensor) or virial.shape != (batch, 3, 3):\n                    raise ValueError(\"physics_info['virial'] must be a torch.Tensor of shape (batch, 3, 3)\")\n            else:\n                virial = torch.zeros(batch, 3, 3, dtype=dtype, device=device)\n\n            # Optional: check for atomic-level virial\n            atomic_virial = physics_info.get('atomic_virial')\n            if atomic_virial is not None:\n                if not isinstance(atomic_virial, torch.Tensor) or atomic_virial.shape != (batch, n_atoms, 9):\n                    raise ValueError(\n                        \"physics_info['atomic_virial'] must be a torch.Tensor of shape (batch, n_atoms, 9)\")\n            else:\n                atomic_virial = torch.zeros(batch, n_atoms, 9, dtype=dtype, device=device)\n\n        # Return all computed quantities\n        return Etot, Ei, force, virial, atomic_virial\n\n    def field(self,\n              element_map: torch.Tensor,\n              central_atoms: torch.Tensor,\n              neighbor_indices: torch.Tensor,\n              neighbor_types: torch.Tensor,\n              neighbor_vectors: torch.Tensor,\n              n_ghost: int) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"\n        Abstract method to be implemented by subclasses. This method defines the core\n        field calculation of the model, which computes atom-wise energies and optionally\n        forces and virial tensors based on atomic environments.\n\n        Parameters\n        ----------\n        element_map : torch.Tensor\n            Tensor of shape [batch, n_atoms], indicating the atomic species (element index)\n            for each atom in the batch.\n\n        central_atoms : torch.Tensor\n            Tensor of shape [batch, n_atoms], representing the type of central atoms.\n\n        neighbor_indices : torch.Tensor\n            Tensor of shape [batch, n_atoms, max_nbr], providing the indices of neighboring\n            atoms for each central atom.\n\n        neighbor_types : torch.Tensor\n            Tensor of shape [batch, n_atoms, max_nbr], indicating the atomic species\n            of neighboring atoms.\n\n        neighbor_vectors : torch.Tensor\n            Tensor of shape [batch, n_atoms, max_nbr, 4], where the last dimension represents\n            (distance, dx, dy, dz), i.e., the norm and vector components of the relative positions.\n\n        n_ghost : int\n            Number of ghost atoms (used to pad or augment neighbor lists, typically for parallelism).\n\n        Returns\n        -------\n        Dict[str, torch.Tensor]\n            A dictionary containing the computed physical quantities:\n            - 'Etot': Total energy, shape [batch, 1].\n            - 'Ei': Atomic energy per atom, shape [batch, n_atoms, 1].\n            - Optional: 'Force': Force on each atom, shape [batch, n_atoms, 3].\n            - Optional: 'virial': Virial tensor, shape [batch, 9].\n            - Optional: 'atomic_virial': virial Force on each atom, shape [batch, n_atoms, 9].\n\n        Note\n        ----\n        This method must be implemented in subclasses of `FieldModel`.\n        \"\"\"\n        return {'Etot': torch.tensor([0.0])}\n</code></pre>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.__init__","title":"<code>__init__(type_map, cutoff, neighbor)</code>","text":"<p>Base class for field-based machine learning potential models.</p>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.__init__--parameters","title":"Parameters","text":"<p>type_map : List[int]     A list mapping atomic species to integer indices used in the model.     For example, [0, 1, 2] might represent three different element types.</p> float <p>Cutoff radius for neighbor searching. Only atoms within this distance will be considered as neighbors.</p> Union[Dict[int, int], int] <p>Maximum number of neighbors for each atom type (or a global value). Used to define tensor sizes or guide model input structure.</p>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.__init__--examples","title":"Examples","text":"<p>```python</p>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.__init__--create-a-model-with-two-element-types-cutoff-radius-60","title":"Create a model with two element types, cutoff radius 6.0,","text":""},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.__init__--and-maximum-100-neighbors-for-element-type-1","title":"and maximum 100 neighbors for element type 1.","text":"<p>model = FieldModel(type_map=[0, 1], cutoff=6.0, neighbor={1: 100})</p> Source code in <code>abfml\\core\\model\\method.py</code> <pre><code>def __init__(self,\n             type_map: List[int],\n             cutoff: float,\n             neighbor: Union[Dict[int, int],int]):\n    \"\"\"\n    Base class for field-based machine learning potential models.\n\n    Parameters\n    ----------\n    type_map : List[int]\n        A list mapping atomic species to integer indices used in the model.\n        For example, [0, 1, 2] might represent three different element types.\n\n    cutoff : float\n        Cutoff radius for neighbor searching.\n        Only atoms within this distance will be considered as neighbors.\n\n    neighbor : Union[Dict[int, int], int]\n        Maximum number of neighbors for each atom type (or a global value).\n        Used to define tensor sizes or guide model input structure.\n\n    Examples\n    --------\n    ```python\n    # Create a model with two element types, cutoff radius 6.0,\n    # and maximum 100 neighbors for element type 1.\n    model = FieldModel(type_map=[0, 1], cutoff=6.0, neighbor={1: 100})\n    \"\"\"\n    super(FieldModel, self).__init__()\n    self.type_map = type_map\n    self.neighbor = neighbor\n    self.cutoff = cutoff\n</code></pre>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.field","title":"<code>field(element_map, central_atoms, neighbor_indices, neighbor_types, neighbor_vectors, n_ghost)</code>","text":"<p>Abstract method to be implemented by subclasses. This method defines the core field calculation of the model, which computes atom-wise energies and optionally forces and virial tensors based on atomic environments.</p>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.field--parameters","title":"Parameters","text":"<p>element_map : torch.Tensor     Tensor of shape [batch, n_atoms], indicating the atomic species (element index)     for each atom in the batch.</p> torch.Tensor <p>Tensor of shape [batch, n_atoms], representing the type of central atoms.</p> torch.Tensor <p>Tensor of shape [batch, n_atoms, max_nbr], providing the indices of neighboring atoms for each central atom.</p> torch.Tensor <p>Tensor of shape [batch, n_atoms, max_nbr], indicating the atomic species of neighboring atoms.</p> torch.Tensor <p>Tensor of shape [batch, n_atoms, max_nbr, 4], where the last dimension represents (distance, dx, dy, dz), i.e., the norm and vector components of the relative positions.</p> int <p>Number of ghost atoms (used to pad or augment neighbor lists, typically for parallelism).</p>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.field--returns","title":"Returns","text":"<p>Dict[str, torch.Tensor]     A dictionary containing the computed physical quantities:     - 'Etot': Total energy, shape [batch, 1].     - 'Ei': Atomic energy per atom, shape [batch, n_atoms, 1].     - Optional: 'Force': Force on each atom, shape [batch, n_atoms, 3].     - Optional: 'virial': Virial tensor, shape [batch, 9].     - Optional: 'atomic_virial': virial Force on each atom, shape [batch, n_atoms, 9].</p>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.field--note","title":"Note","text":"<p>This method must be implemented in subclasses of <code>FieldModel</code>.</p> Source code in <code>abfml\\core\\model\\method.py</code> <pre><code>def field(self,\n          element_map: torch.Tensor,\n          central_atoms: torch.Tensor,\n          neighbor_indices: torch.Tensor,\n          neighbor_types: torch.Tensor,\n          neighbor_vectors: torch.Tensor,\n          n_ghost: int) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"\n    Abstract method to be implemented by subclasses. This method defines the core\n    field calculation of the model, which computes atom-wise energies and optionally\n    forces and virial tensors based on atomic environments.\n\n    Parameters\n    ----------\n    element_map : torch.Tensor\n        Tensor of shape [batch, n_atoms], indicating the atomic species (element index)\n        for each atom in the batch.\n\n    central_atoms : torch.Tensor\n        Tensor of shape [batch, n_atoms], representing the type of central atoms.\n\n    neighbor_indices : torch.Tensor\n        Tensor of shape [batch, n_atoms, max_nbr], providing the indices of neighboring\n        atoms for each central atom.\n\n    neighbor_types : torch.Tensor\n        Tensor of shape [batch, n_atoms, max_nbr], indicating the atomic species\n        of neighboring atoms.\n\n    neighbor_vectors : torch.Tensor\n        Tensor of shape [batch, n_atoms, max_nbr, 4], where the last dimension represents\n        (distance, dx, dy, dz), i.e., the norm and vector components of the relative positions.\n\n    n_ghost : int\n        Number of ghost atoms (used to pad or augment neighbor lists, typically for parallelism).\n\n    Returns\n    -------\n    Dict[str, torch.Tensor]\n        A dictionary containing the computed physical quantities:\n        - 'Etot': Total energy, shape [batch, 1].\n        - 'Ei': Atomic energy per atom, shape [batch, n_atoms, 1].\n        - Optional: 'Force': Force on each atom, shape [batch, n_atoms, 3].\n        - Optional: 'virial': Virial tensor, shape [batch, 9].\n        - Optional: 'atomic_virial': virial Force on each atom, shape [batch, n_atoms, 9].\n\n    Note\n    ----\n    This method must be implemented in subclasses of `FieldModel`.\n    \"\"\"\n    return {'Etot': torch.tensor([0.0])}\n</code></pre>"},{"location":"api/core/model/method/#abfml.core.model.method.FieldModel.forward","title":"<code>forward(element_map, central_atoms, neighbor_indices, neighbor_types, neighbor_vectors, n_ghost)</code>","text":"<p>Main forward pass computing physical quantities Args:     element_map: Atomic numbers mapped to indices [batch, n_atoms]     central_atoms: Central atom indices [batch, n_atoms]     neighbor_indices: Neighbor atom indices [batch, n_atoms, max_nbr]     neighbor_types: Neighbor atom types [batch, n_atoms, max_nbr]     neighbor_vectors: Relative position vectors [batch, n_atoms, max_nbr, 4]                       (distance, dx, dy, dz)     n_ghost: Number of ghost atoms in the system</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tuple containing:</p> <code>Tensor</code> <ul> <li>Etot [batch, 1]</li> </ul> <code>Tensor</code> <ul> <li>Ei [batch, n_atoms, 1]</li> </ul> <code>Tensor</code> <ul> <li>force [batch, n_atoms, 3]</li> </ul> <code>Tensor</code> <ul> <li>virial tensor [batch, 9]</li> </ul> <code>Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]</code> <ul> <li>atomic_virial [batch, n_atoms, 9]</li> </ul> Source code in <code>abfml\\core\\model\\method.py</code> <pre><code>def forward(self,\n            element_map: torch.Tensor,\n            central_atoms: torch.Tensor,\n            neighbor_indices: torch.Tensor,\n            neighbor_types: torch.Tensor,\n            neighbor_vectors: torch.Tensor,\n            n_ghost: int) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Main forward pass computing physical quantities\n    Args:\n        element_map: Atomic numbers mapped to indices [batch, n_atoms]\n        central_atoms: Central atom indices [batch, n_atoms]\n        neighbor_indices: Neighbor atom indices [batch, n_atoms, max_nbr]\n        neighbor_types: Neighbor atom types [batch, n_atoms, max_nbr]\n        neighbor_vectors: Relative position vectors [batch, n_atoms, max_nbr, 4]\n                          (distance, dx, dy, dz)\n        n_ghost: Number of ghost atoms in the system\n\n    Returns:\n        Tuple containing:\n        - Etot [batch, 1]\n        - Ei [batch, n_atoms, 1]\n        - force [batch, n_atoms, 3]\n        - virial tensor [batch, 9]\n        - atomic_virial [batch, n_atoms, 9]\n    \"\"\"\n    # Extract dimensions and tensor properties\n    batch, n_atoms, max_neighbor, _ = neighbor_vectors.shape\n    device, dtype = neighbor_vectors.device, neighbor_vectors.dtype\n\n    # Extract displacement vectors (dx, dy, dz) and enable autograd\n    relative_positions = neighbor_vectors[..., 1:]\n    relative_positions.requires_grad_(True)\n\n    # Recalculate distance norm for generalization and recombine into input vector\n    distance = torch.norm(relative_positions, dim=-1, keepdim=True)  # Shape: [batch, n_atoms, max_nbr, 1]\n    neighbor_vector = torch.cat([distance, relative_positions], dim=-1)  # Shape: [batch, n_atoms, max_nbr, 4]\n\n    # Call the user-defined field function to compute energy and optionally other properties\n    physics_info = self.field(\n        element_map=element_map,\n        central_atoms=central_atoms,\n        neighbor_indices=neighbor_indices,\n        neighbor_types=neighbor_types,\n        neighbor_vectors=neighbor_vector,\n        n_ghost=n_ghost\n    )\n\n    # Required outputs\n    Etot = physics_info['Etot']  # Total energy per configuration, shape: [batch, 1]\n    Ei = physics_info['Ei']  # Per-atom energy, shape: [batch, n_atoms, 1]\n\n    # Validate required outputs\n    if Etot is None or not isinstance(Etot, torch.Tensor) or Etot.shape != (batch, 1):\n        raise ValueError(\"physics_info['Etot'] must be a torch.Tensor of shape (batch, 1)\")\n    if Ei is None or not isinstance(Ei, torch.Tensor) or Ei.shape != (batch, n_atoms, 1):\n        raise ValueError(\"physics_info['Ei'] must be a torch.Tensor of shape (batch, n_atoms, 1)\")\n\n    # If force is not provided, compute it via autograd\n    if physics_info.get('Force') is None:\n        # Create a gradient mask for backpropagation\n        energy_mask: List[Optional[torch.Tensor]] = [torch.ones_like(Ei)]\n\n        # Compute gradient of Ei with respect to atomic positions\n        grad_Ei = torch.autograd.grad(\n            outputs=[Ei],\n            inputs=[relative_positions],\n            grad_outputs=energy_mask,\n            retain_graph=True,\n            create_graph=True\n        )[0]\n        assert grad_Ei is not None\n\n        # Compute force, virial tensor, and atomic-level virial from gradients\n        force, virial, atomic_virial = derive_mechanics(\n            grad_Ei=grad_Ei,\n            neighbor_vectors=neighbor_vector,\n            neighbor_indices=neighbor_indices,\n            n_ghost=n_ghost\n        )\n    else:\n        # If force is provided by field, validate its shape\n        force = physics_info['Force']\n        if not isinstance(force, torch.Tensor) or force.shape != (batch, n_atoms, 3):\n            raise ValueError(\"physics_info['Force'] must be a torch.Tensor of shape (batch, n_atoms, 3)\")\n\n        # Optional: check for virial tensor\n        virial = physics_info.get('virial')\n        if virial is not None:\n            if not isinstance(virial, torch.Tensor) or virial.shape != (batch, 3, 3):\n                raise ValueError(\"physics_info['virial'] must be a torch.Tensor of shape (batch, 3, 3)\")\n        else:\n            virial = torch.zeros(batch, 3, 3, dtype=dtype, device=device)\n\n        # Optional: check for atomic-level virial\n        atomic_virial = physics_info.get('atomic_virial')\n        if atomic_virial is not None:\n            if not isinstance(atomic_virial, torch.Tensor) or atomic_virial.shape != (batch, n_atoms, 9):\n                raise ValueError(\n                    \"physics_info['atomic_virial'] must be a torch.Tensor of shape (batch, n_atoms, 9)\")\n        else:\n            atomic_virial = torch.zeros(batch, n_atoms, 9, dtype=dtype, device=device)\n\n    # Return all computed quantities\n    return Etot, Ei, force, virial, atomic_virial\n</code></pre>"},{"location":"api/core/model/method/#abfml.core.model.method.NormalModel","title":"<code>NormalModel</code>","text":"Source code in <code>abfml\\core\\model\\method.py</code> <pre><code>class NormalModel:\n    def __init__(self,\n                 normal_data,\n                 param_class: Param,\n                 normal_rate: Union[float, str] = 'auto',\n                 is_get_energy_shift: bool = False):\n        self.param_class = param_class\n        self.normal_loader = NormalModel.normal_data_loader(need_data=normal_data, normal_rate=normal_rate)\n        self.is_get_energy_shift = is_get_energy_shift\n        self.normal_data = tuple([])\n\n    def initialize(self):\n        normal_data = self.normal(normal_loader=self.normal_loader, param_class=self.param_class)\n\n        if isinstance(normal_data, tuple):\n            self.normal_data = normal_data\n        else:\n            self.normal_data = tuple([normal_data])\n\n        if self.is_get_energy_shift:\n            energy_shift = NormalModel.get_energy_shift(need_data=self.normal_loader, type_map=self.param_class.GlobalSet.type_map)\n            self.normal_data = tuple([energy_shift]) + self.normal_data\n\n    @staticmethod\n    def normal_data_loader(need_data, normal_rate: Union[float, str]) -&gt; DataLoader:\n        total_image_num = len(need_data)\n        total_indices = np.arange(total_image_num)\n        if isinstance(normal_rate, float):\n            if normal_rate &lt;= 1.0:\n                num = int(total_image_num * normal_rate + 1)\n            else:\n                raise Exception(\"rate\")\n        elif normal_rate == \"auto\":\n            if total_image_num * 0.1 &lt; 100:\n                num = total_image_num\n            else:\n                num = int(total_image_num * 0.1 + 1)\n        else:\n            raise Exception(\"rate\")\n        np.random.shuffle(total_indices)\n        normal_indices = total_indices[:num]\n        normal_data = Subset(need_data, normal_indices)\n        num_threads = torch.get_num_threads()\n        num_worker = int(num_threads / 2)\n        normal_data_loader = DataLoader(normal_data, batch_size=1, shuffle=True, num_workers=num_worker)\n\n        return normal_data_loader\n\n    @staticmethod\n    def get_energy_shift(need_data, type_map: List[int]) -&gt; List[float]:\n        ntype = len(type_map)\n        type_num = torch.zeros(ntype)\n        energy_shift = [0.0] * ntype\n        for i, image_batch in enumerate(need_data):\n            central_atoms = image_batch[\"central_atoms\"]\n            element_types = image_batch[\"element_types\"][0].to(torch.int64).tolist()\n            for i_type, element in enumerate(element_types):\n                mask = (central_atoms == element)\n                indices = type_map.index(element)\n                type_num[indices] += 1\n                try:\n                    energy = torch.mean(image_batch[\"energy\"] / image_batch[\"n_atoms\"]).item()\n                    energy_shift[indices] = energy_shift[indices] + energy\n                except KeyError:\n                    try:\n                        Ei = torch.mean(image_batch[\"atomic_energy\"][mask]).item()\n                        energy_shift[indices] = energy_shift[indices] + Ei\n                    except KeyError:\n                        energy_shift[indices] = energy_shift[indices] + np.random.uniform(-10.0, 0.0)\n\n        type_num[type_num == 0] = 1\n        for i, i_energy in enumerate(energy_shift):\n            energy_shift[i] = (i_energy / type_num[i]).item()\n\n        return energy_shift\n\n    def normal(self, normal_loader, param_class):\n        return None\n</code></pre>"},{"location":"api/core/model/method/#abfml.core.model.method.Param","title":"<code>Param</code>","text":"Source code in <code>abfml\\param\\param.py</code> <pre><code>class Param:\n    def __init__(self, input_dict: dict):\n        self.input_dict_new = {}\n        global_dict = input_dict['global_setting']\n        validator = DefaultValidatingDraft7Validator(global_set_schema)\n        validator.validate(global_dict)\n        self.GlobalSet = GlobalSet(**global_dict)\n        if isinstance(self.GlobalSet.neighbor, list):\n            self.GlobalSet.neighbor = {t: n for t, n in zip(self.GlobalSet.type_map, self.GlobalSet.neighbor)}\n\n        data_dict = input_dict['data_setting']\n        validator = DefaultValidatingDraft7Validator(data_set_schema)\n        validator.validate(data_dict)\n        self.DataSet = DataSet(**data_dict)\n\n        train_dict = input_dict['train_setting']\n        validator = DefaultValidatingDraft7Validator(train_set_schema)\n        validator.validate(train_dict)\n        self.TrainSet = TrainSet(**train_dict)\n\n        loss_dict = input_dict['loss_setting']\n        validator = DefaultValidatingDraft7Validator(loss_set_schema)\n        validator.validate(loss_dict)\n        self.LossSet = LossSet(**loss_dict)\n\n        learning_rate_dict = input_dict['learning_rate']\n        validator = DefaultValidatingDraft7Validator(learning_rate_schema)\n        validator.validate(learning_rate_dict)\n        self.LrSet = LrSet(**learning_rate_dict)\n\n        self.model_name = input_dict['model_setting']['name']\n        if input_dict['model_setting']['name'] in ['dp_se_e2_a', 'dp_se_e2_r', 'dp_se_e3']:\n            fitting_config = input_dict['model_setting']['fitting_net']\n            embedding_config = input_dict['model_setting']['descriptor']\n            self.DeepSe = DeepSe(fitting_config=fitting_config, embedding_config=embedding_config)\n        elif input_dict['model_setting']['name'] == 'BPMlp':\n            fitting_config = input_dict['model_setting']['fitting_net']\n            feature_config = input_dict['model_setting']['descriptor']\n            self.BPDescriptor = BPDescriptor(fitting_config=fitting_config, feature_config=feature_config)\n        elif input_dict['model_setting']['name'] == \"NEP\":\n            fitting_config = input_dict['model_setting']['fitting_net']\n            feature_config = input_dict['model_setting']['descriptor']\n            self.NEPParam = NEPParam(fitting_config=fitting_config, feature_config=feature_config)\n        elif input_dict['model_setting']['name'] == \"test\":\n            self.test = self.Test(input_dict[\"model_setting\"])\n        elif input_dict['model_setting']['name'] == \"user_defined\":\n            self.user_defined = self.UserDefined(input_dict[\"model_setting\"])\n\n        else:\n            raise Exception(f\"Undefined keyword: , Please read the manual!\")\n\n    class Test:\n        def __init__(self, input_dict):\n            self.input_dict = input_dict\n\n    class UserDefined:\n        config: dict = {}\n        model_path: str = \"\"\n        field_name: str = \"\"\n        normal_name: str = None\n\n        def __init__(self, config: dict):\n            if 'descriptor' in config.keys():\n                self.config = config[\"descriptor\"]\n            else:\n                raise Exception(\"Please write the custom parameters in the descriptor\")\n\n            if \"model_path\" in config.keys():\n                self.model_path = config[\"model_path\"]\n            else:\n                raise Exception(\"Undefined model path:{model_path} ?\")\n\n            self.field_name = config[\"field_name\"]\n\n            if \"normal_name\" in config.keys():\n                self.normal_name = config[\"normal_name\"]\n            else:\n                self.normal_name = None\n</code></pre>"},{"location":"api/core/model/method/#abfml.core.model.method.derive_mechanics","title":"<code>derive_mechanics(grad_Ei, neighbor_vectors, neighbor_indices, n_ghost)</code>","text":"Source code in <code>abfml\\core\\model\\math_fun.py</code> <pre><code>def derive_mechanics(\n    grad_Ei: torch.Tensor,\n    neighbor_vectors: torch.Tensor,\n    neighbor_indices: torch.Tensor,\n    n_ghost: int\n) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    batch, n_atoms, max_neighbors = neighbor_indices.shape\n    dtype, device = neighbor_vectors.dtype, neighbor_vectors.device\n\n    # Initialize force and per-atom virial tensors\n    force = torch.zeros(batch, n_atoms + n_ghost, 3, dtype=dtype, device=device)\n    force[:, :n_atoms, :] = grad_Ei.sum(dim=-2)  # Direct contribution from central atoms\n\n    atomic_virial = torch.zeros(batch, n_atoms + n_ghost, 9, dtype=dtype, device=device)\n\n    # Extract relative position vectors (exclude norm)\n    rel_pos = neighbor_vectors[..., 1:]  # Shape: [batch, n_atoms, max_neighbors, 3]\n\n    # Compute local virial contributions via outer product of dr and dE\n    local_virials = torch.matmul(rel_pos.unsqueeze(-1), -1 * grad_Ei.unsqueeze(-2)).reshape(batch, n_atoms, max_neighbors, 9)\n\n    # Replace invalid neighbor indices (-1) with 0\n    neighbor_indices[neighbor_indices == -1] = 0\n\n    for b in range(batch):\n        # Flatten indices and contribution values\n        neighbor_idx_b = neighbor_indices[b].view(-1).to(torch.int64)\n\n        # Force scatter-add\n        force_contrib_b = -1 * grad_Ei[b].view(-1, 3)\n        index_f = neighbor_idx_b.unsqueeze(-1).expand(-1, 3)\n        force[b] = force[b].scatter_add(0, index_f, force_contrib_b)\n\n        # Virial scatter-add\n        virial_contrib_b = local_virials[b].view(-1, 9)\n        index_v = neighbor_idx_b.unsqueeze(-1).expand(-1, 9)\n        atomic_virial[b] = atomic_virial[b].scatter_add(0, index_v, virial_contrib_b)\n\n    # Compute total virial by summing over all atoms\n    virial = atomic_virial.sum(dim=1)\n\n    return force, virial, atomic_virial\n</code></pre>"}]}